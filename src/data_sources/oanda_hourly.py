"""
OANDAæ™‚é–“è¶³ãƒ‡ãƒ¼ã‚¿åé›†
ã™ã¹ã¦ã®ä¸Šä¸‹ç§»å‹•ã‚’æ‰ãˆã‚‹ãŸã‚ã®é«˜é »åº¦ãƒ‡ãƒ¼ã‚¿å–å¾—
"""
from pathlib import Path
from datetime import datetime, timedelta
from loguru import logger
import pandas as pd
import time
from typing import List, Optional

from ..api.oanda_client import OandaClient


class OandaHourlyData:
    """OANDAæ™‚é–“è¶³ãƒ‡ãƒ¼ã‚¿åé›†"""

    def __init__(self, granularity: str = 'H1'):
        """
        Args:
            granularity: æ™‚é–“è¶³ã®ç²’åº¦
                - H1: 1æ™‚é–“è¶³ï¼ˆæœ€é«˜é »åº¦ï¼‰
                - H4: 4æ™‚é–“è¶³ï¼ˆä¸­é »åº¦ï¼‰
                - D: æ—¥è¶³ï¼ˆç¾åœ¨ä½¿ç”¨ä¸­ï¼‰
        """
        self.client = OandaClient()
        self.granularity = granularity
        self.data_dir = Path('data/hourly')
        self.data_dir.mkdir(parents=True, exist_ok=True)

        logger.info(f"OANDAæ™‚é–“è¶³ãƒ‡ãƒ¼ã‚¿åé›† åˆæœŸåŒ–: {granularity}")

    def get_hourly_data(
        self,
        instrument: str = 'USD_JPY',
        days: int = 730,  # 2å¹´åˆ†
        save: bool = True
    ) -> pd.DataFrame:
        """
        å¤§é‡ã®æ™‚é–“è¶³ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆæœ€æ–°ã®countãƒ‡ãƒ¼ã‚¿ã®ã¿ï¼‰

        Note: OANDA APIã®åˆ¶é™ã«ã‚ˆã‚Šã€ä¸€åº¦ã«å–å¾—ã§ãã‚‹ã®ã¯æœ€æ–°500æœ¬ã¾ã§ã€‚
              2å¹´åˆ†ã®å…¨ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹ã«ã¯ã€Yahoo Financeã®æ–¹ãŒé©ã—ã¦ã„ã‚‹å¯èƒ½æ€§ã‚ã‚Šã€‚

        Args:
            instrument: é€šè²¨ãƒšã‚¢
            days: å–å¾—æ—¥æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ730æ—¥ = 2å¹´ï¼‰
            save: CSVã«ä¿å­˜ã™ã‚‹ã‹

        Returns:
            æ™‚é–“è¶³ãƒ‡ãƒ¼ã‚¿ã®DataFrame
        """
        logger.info(f"{instrument} {self.granularity}ãƒ‡ãƒ¼ã‚¿å–å¾—é–‹å§‹")

        # ã¾ãšæœ€æ–°500æœ¬ã‚’å–å¾—
        try:
            logger.info("æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
            df = self.client.get_historical_data(
                instrument=instrument,
                granularity=self.granularity,
                count=500  # æœ€å¤§500æœ¬
            )

            if df.empty:
                raise ValueError("ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")

            logger.info(f"âœ… å–å¾—å®Œäº†: {len(df)}æœ¬ã®ãƒ­ãƒ¼ã‚½ã‚¯è¶³")
            logger.info(f"æœŸé–“: {df.index.min()} ~ {df.index.max()}")
            logger.info(f"âš ï¸ OANDA APIã®åˆ¶é™ã«ã‚ˆã‚Šã€æœ€æ–°500æœ¬ã®ã¿å–å¾—")
            logger.info(f"ğŸ’¡ ã‚ˆã‚Šé•·æœŸãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ãªå ´åˆã¯ã€Yahoo Financeã‚’æ¤œè¨ã—ã¦ãã ã•ã„")

            # ä¿å­˜
            if save:
                filename = f"{instrument}_{self.granularity}_latest.csv"
                filepath = self.data_dir / filename
                df.to_csv(filepath)
                logger.info(f"ğŸ’¾ ä¿å­˜: {filepath}")

            return df

        except Exception as e:
            logger.error(f"ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            raise

    def _calculate_total_candles(self, days: int) -> int:
        """å¿…è¦ãªãƒ­ãƒ¼ã‚½ã‚¯è¶³æ•°ã‚’è¨ˆç®—"""
        if self.granularity == 'H1':
            # 1æ™‚é–“è¶³: 1æ—¥24æœ¬ï¼ˆåœŸæ—¥é™¤å¤–ã§ç´„20æœ¬/æ—¥ï¼‰
            return days * 20
        elif self.granularity == 'H4':
            # 4æ™‚é–“è¶³: 1æ—¥6æœ¬ï¼ˆåœŸæ—¥é™¤å¤–ã§ç´„5æœ¬/æ—¥ï¼‰
            return days * 5
        elif self.granularity == 'D':
            # æ—¥è¶³: 1æ—¥1æœ¬ï¼ˆåœŸæ—¥é™¤å¤–ã§ç´„0.7æœ¬/æ—¥ï¼‰
            return days
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
            return days * 20

    def get_multi_currency_data(
        self,
        instruments: List[str] = ['USD_JPY', 'EUR_USD', 'GBP_USD', 'EUR_JPY'],
        days: int = 730
    ) -> dict:
        """
        è¤‡æ•°é€šè²¨ãƒšã‚¢ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€æ‹¬å–å¾—

        Args:
            instruments: é€šè²¨ãƒšã‚¢ã®ãƒªã‚¹ãƒˆ
            days: å–å¾—æ—¥æ•°

        Returns:
            {é€šè²¨ãƒšã‚¢: DataFrame} ã®è¾æ›¸
        """
        logger.info(f"è¤‡æ•°é€šè²¨ãƒšã‚¢ãƒ‡ãƒ¼ã‚¿å–å¾—é–‹å§‹: {len(instruments)}ãƒšã‚¢")

        results = {}
        for instrument in instruments:
            try:
                logger.info(f"\n{'='*60}")
                logger.info(f"é€šè²¨ãƒšã‚¢: {instrument}")
                logger.info(f"{'='*60}")

                df = self.get_hourly_data(
                    instrument=instrument,
                    days=days,
                    save=True
                )
                results[instrument] = df

                # é€šè²¨ãƒšã‚¢é–“ã§1ç§’å¾…æ©Ÿï¼ˆAPIãƒ¬ãƒ¼ãƒˆåˆ¶é™ï¼‰
                time.sleep(1)

            except Exception as e:
                logger.error(f"{instrument} ã®ãƒ‡ãƒ¼ã‚¿å–å¾—ã«å¤±æ•—: {e}")
                continue

        logger.info(f"\nâœ… è¤‡æ•°é€šè²¨ãƒšã‚¢ãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº†: {len(results)}/{len(instruments)}ãƒšã‚¢")
        return results

    def load_saved_data(self, instrument: str, days: int = 730) -> Optional[pd.DataFrame]:
        """ä¿å­˜æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        filename = f"{instrument}_{self.granularity}_{days}days.csv"
        filepath = self.data_dir / filename

        if filepath.exists():
            logger.info(f"ä¿å­˜æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {filepath}")
            df = pd.read_csv(filepath, index_col='time', parse_dates=True)
            logger.info(f"âœ… èª­ã¿è¾¼ã¿å®Œäº†: {len(df)}æœ¬")
            return df
        else:
            logger.warning(f"ä¿å­˜æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {filepath}")
            return None


def collect_all_hourly_data():
    """ã™ã¹ã¦ã®é€šè²¨ãƒšã‚¢ã®æ™‚é–“è¶³ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ï¼ˆãƒ¡ã‚¤ãƒ³å®Ÿè¡Œï¼‰"""
    logger.info("="*80)
    logger.info("ä¸–ç•Œæœ€å¼·ã‚·ã‚¹ãƒ†ãƒ  - æ™‚é–“è¶³ãƒ‡ãƒ¼ã‚¿åé›†é–‹å§‹")
    logger.info("="*80)

    # H1ï¼ˆ1æ™‚é–“è¶³ï¼‰ã§åé›†
    collector = OandaHourlyData(granularity='H1')

    # å¯¾è±¡é€šè²¨ãƒšã‚¢
    instruments = [
        'USD_JPY',   # æ—¥æœ¬æ™‚é–“ã«å¼·ã„
        'EUR_USD',   # æ¬§å·ãƒ»ç±³å›½æ™‚é–“ã«å¼·ã„
        'GBP_USD',   # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£é«˜ã„
        'EUR_JPY',   # ã‚¯ãƒ­ã‚¹å††ã®ä»£è¡¨
    ]

    # 2å¹´åˆ†ã®ãƒ‡ãƒ¼ã‚¿å–å¾—
    results = collector.get_multi_currency_data(
        instruments=instruments,
        days=730
    )

    # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
    logger.info("\n" + "="*80)
    logger.info("ãƒ‡ãƒ¼ã‚¿åé›†ã‚µãƒãƒªãƒ¼")
    logger.info("="*80)
    for instrument, df in results.items():
        logger.info(f"{instrument}:")
        logger.info(f"  ãƒ­ãƒ¼ã‚½ã‚¯è¶³æ•°: {len(df)}")
        logger.info(f"  æœŸé–“: {df.index.min()} ~ {df.index.max()}")
        logger.info(f"  å®Œå…¨æ€§: {(1 - df.isnull().sum().sum() / (len(df) * len(df.columns))) * 100:.1f}%")

    logger.info("\nâœ… ã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿åé›†å®Œäº†ï¼")
    return results


if __name__ == '__main__':
    collect_all_hourly_data()
